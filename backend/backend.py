# -*- coding: utf-8 -*-
"""backend.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1N0HCXkeXisuTWJa5RtOqqMfZrEWKBeln

## env
"""

from google.colab import drive
drive.mount('/content/drive')

"""# audio pre processing"""

import librosa, librosa.display
import matplotlib.pyplot as plt
import numpy as np
import os
from sklearn import preprocessing
import tensorflow as tf
import keras.backend as K
import backend_config as config

def to_3_channels(spectro):
  xi = spectro[:60, :]
  xi = np.expand_dims(xi, axis=2)
  for i in range(1,3):
    xy = spectro[i*30 : (i+2)*30, :]
    xy = np.expand_dims(xy, axis=2)
    xi = np.dstack((xi, xy))
  return xi

def convert_wav_to_melSpectrogram(wav_file):
    # number of samples in a window per fft
    n_fft = 2048
    hop_length = 256
    signal, sr = librosa.core.load(wav_file)
    mel_spect = librosa.feature.melspectrogram(y=signal, sr=sr, hop_length=hop_length, 
 n_fft=n_fft) 
    mel_spect = librosa.power_to_db(mel_spect, ref=np.max)
    mel_spect = np.abs(mel_spect)
    return mel_spect

def load_anchor_files(dirname):
    X = []
    audio_files = os.listdir(dirname)
    audio_files = [a for a in audio_files if not a.startswith('.') ]  # ignoring any hidden files in the read directory
    if len(audio_files) > 0:
      for filename in audio_files:
        spectro = convert_wav_to_melSpectrogram(os.path.join(dirname, filename))
        spectro = preprocessing.normalize(spectro)
        frames = spectro.shape[1] / 87
        X_frame = []
        
        if frames >= 2:
          spectro = spectro[:, -174:] 
          for i in range(0, 171, 43):
            frame = spectro[:,i:i+87]   # creating 3 frames for 2 secs audio
            if frame.shape[1] == 87:
              X3_frame = to_3_channels(frame)
              X_frame += features(np.expand_dims(X3_frame, 0))
        elif frames >= 1:
          spectro = spectro[:, -132:]
          for i in range(0, 130, 43):
            frame = spectro[:,i:i+87] 
            if frame.shape[1] == 87:
              X3_frame = to_3_channels(frame)
              X_frame += [features(np.expand_dims(X3_frame, 0))]
        X += [X_frame]  
        X = np.array(X)
        ex = sum(X)/(len(X))
    return ex #np.array(X)

def load_stream_files(dirname):
    X = []
    audio_files = os.listdir(dirname)
    audio_files = [a for a in audio_files if not a.startswith('.') ]  # ignoring any hidden files in the read directory
    if len(audio_files) > 0:
      for filename in audio_files:
        spectro = convert_wav_to_melSpectrogram(os.path.join(dirname, filename))
        spectro = preprocessing.normalize(spectro)
        frames = spectro.shape[1] / 87
        
        if frames >= 2:
          spectro = spectro[:, -174:] 
          for i in range(0, 171, 43):
            frame = spectro[:,i:i+87]   # creating 3 frames for 2 secs audio
            if frame.shape[1] == 87:
              X += [to_3_channels(frame)]
          
        elif frames >= 1:
          spectro = spectro[:, -132:]
          for i in range(0, 130, 43):
            frame = spectro[:,i:i+87] 
            if frame.shape[1] == 87:
              X += [to_3_channels(frame)]
        # X += [X_frame]  
        # X = np.array(X)
        # ex = sum(X)/(len(X))
    return np.array(X)

# os.listdir(config.streaming_files_path)

"""# feature extraction"""

features = tf.keras.models.load_model(config.feature_model_path)
confidence = tf.keras.models.load_model(config.confidence_model_path)

"""# wake word detection"""

# anchors = load_anchor_files(config.anchor_path)

# anchors[0].shape

def generate_features(streaming_files_path):
  frame_spectrums = load_stream_files(streaming_files_path)
  frame_features = [features(np.expand_dims(frame, 0)) for frame in frame_spectrums]
  return frame_features



def wake(anchors, streaming_files_path, threshold):
  stream_vectors = generate_features(streaming_files_path)
  # minlen(anchors)
  for stream in stream_vectors:
    if all(confidence([anchor, stream]) > threshold for anchor in anchors):
      return True
  return False

def app(anchor_path, streaming_files_path, threshold):
  anchors = load_anchor_files(anchor_path)
  if(wake(anchors, streaming_files_path, threshold)):
    print("hello! How can I help you")

app(config.anchor_path, config.streaming_files_path, config.threshold)

